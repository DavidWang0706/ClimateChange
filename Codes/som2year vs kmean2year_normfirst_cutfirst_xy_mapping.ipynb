{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6dc4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.ma.core import ceil\n",
    "from scipy.spatial import distance #distance calculation\n",
    "from sklearn.preprocessing import MinMaxScaler #normalisation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score #scoring\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import animation, colors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214bc26e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>222.1</th>\n",
       "      <th>223.1</th>\n",
       "      <th>224.1</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266183</td>\n",
       "      <td>0.267322</td>\n",
       "      <td>0.267839</td>\n",
       "      <td>0.268356</td>\n",
       "      <td>0.269669</td>\n",
       "      <td>0.271125</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.274101</td>\n",
       "      <td>0.276006</td>\n",
       "      <td>0.277690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024460</td>\n",
       "      <td>0.024566</td>\n",
       "      <td>0.025473</td>\n",
       "      <td>0.920792</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.548938</td>\n",
       "      <td>0.548604</td>\n",
       "      <td>0.548087</td>\n",
       "      <td>0.547053</td>\n",
       "      <td>0.546066</td>\n",
       "      <td>0.545360</td>\n",
       "      <td>0.544935</td>\n",
       "      <td>0.543512</td>\n",
       "      <td>0.542081</td>\n",
       "      <td>0.540682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390762</td>\n",
       "      <td>0.397230</td>\n",
       "      <td>0.405797</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357846</td>\n",
       "      <td>0.355222</td>\n",
       "      <td>0.353671</td>\n",
       "      <td>0.352637</td>\n",
       "      <td>0.352484</td>\n",
       "      <td>0.353033</td>\n",
       "      <td>0.354286</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.358599</td>\n",
       "      <td>0.361680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064879</td>\n",
       "      <td>0.068301</td>\n",
       "      <td>0.073843</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.357846</td>\n",
       "      <td>0.355222</td>\n",
       "      <td>0.353671</td>\n",
       "      <td>0.352637</td>\n",
       "      <td>0.352484</td>\n",
       "      <td>0.353033</td>\n",
       "      <td>0.354286</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.358599</td>\n",
       "      <td>0.361680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064879</td>\n",
       "      <td>0.068301</td>\n",
       "      <td>0.073843</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.395650</td>\n",
       "      <td>0.389866</td>\n",
       "      <td>0.385729</td>\n",
       "      <td>0.382110</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>0.378953</td>\n",
       "      <td>0.378182</td>\n",
       "      <td>0.378843</td>\n",
       "      <td>0.378986</td>\n",
       "      <td>0.380577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038095</td>\n",
       "      <td>0.039508</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>0.859658</td>\n",
       "      <td>0.870734</td>\n",
       "      <td>0.885212</td>\n",
       "      <td>0.897622</td>\n",
       "      <td>0.903209</td>\n",
       "      <td>0.907206</td>\n",
       "      <td>0.908052</td>\n",
       "      <td>0.908286</td>\n",
       "      <td>0.905907</td>\n",
       "      <td>0.900787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923706</td>\n",
       "      <td>0.930254</td>\n",
       "      <td>0.939836</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0.916624</td>\n",
       "      <td>0.919855</td>\n",
       "      <td>0.928128</td>\n",
       "      <td>0.934333</td>\n",
       "      <td>0.938406</td>\n",
       "      <td>0.943494</td>\n",
       "      <td>0.947013</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>0.952953</td>\n",
       "      <td>0.955381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966330</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.972835</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>0.932160</td>\n",
       "      <td>0.934850</td>\n",
       "      <td>0.934850</td>\n",
       "      <td>0.935884</td>\n",
       "      <td>0.937371</td>\n",
       "      <td>0.938310</td>\n",
       "      <td>0.940260</td>\n",
       "      <td>0.941636</td>\n",
       "      <td>0.944067</td>\n",
       "      <td>0.949606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970248</td>\n",
       "      <td>0.974210</td>\n",
       "      <td>0.970785</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0.879855</td>\n",
       "      <td>0.885729</td>\n",
       "      <td>0.891417</td>\n",
       "      <td>0.895553</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.900985</td>\n",
       "      <td>0.902338</td>\n",
       "      <td>0.903075</td>\n",
       "      <td>0.903293</td>\n",
       "      <td>0.902887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945185</td>\n",
       "      <td>0.950480</td>\n",
       "      <td>0.956458</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.868980</td>\n",
       "      <td>0.876422</td>\n",
       "      <td>0.886763</td>\n",
       "      <td>0.889866</td>\n",
       "      <td>0.889234</td>\n",
       "      <td>0.883359</td>\n",
       "      <td>0.889870</td>\n",
       "      <td>0.895779</td>\n",
       "      <td>0.904861</td>\n",
       "      <td>0.915486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996315</td>\n",
       "      <td>0.994842</td>\n",
       "      <td>0.994092</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>737 rows × 457 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.266183  0.267322  0.267839  0.268356  0.269669  0.271125  0.272727   \n",
       "1    0.548938  0.548604  0.548087  0.547053  0.546066  0.545360  0.544935   \n",
       "2    0.357846  0.355222  0.353671  0.352637  0.352484  0.353033  0.354286   \n",
       "3    0.357846  0.355222  0.353671  0.352637  0.352484  0.353033  0.354286   \n",
       "4    0.395650  0.389866  0.385729  0.382110  0.380435  0.378953  0.378182   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "732  0.859658  0.870734  0.885212  0.897622  0.903209  0.907206  0.908052   \n",
       "733  0.916624  0.919855  0.928128  0.934333  0.938406  0.943494  0.947013   \n",
       "734  0.932160  0.934850  0.934850  0.935884  0.937371  0.938310  0.940260   \n",
       "735  0.879855  0.885729  0.891417  0.895553  0.898551  0.900985  0.902338   \n",
       "736  0.868980  0.876422  0.886763  0.889866  0.889234  0.883359  0.889870   \n",
       "\n",
       "            7         8         9  ...     222.1     223.1     224.1  \\\n",
       "0    0.274101  0.276006  0.277690  ...  0.024460  0.024566  0.025473   \n",
       "1    0.543512  0.542081  0.540682  ...  0.390762  0.397230  0.405797   \n",
       "2    0.356436  0.358599  0.361680  ...  0.064879  0.068301  0.073843   \n",
       "3    0.356436  0.358599  0.361680  ...  0.064879  0.068301  0.073843   \n",
       "4    0.378843  0.378986  0.380577  ...  0.038095  0.039508  0.041927   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "732  0.908286  0.905907  0.900787  ...  0.923706  0.930254  0.939836   \n",
       "733  0.950495  0.952953  0.955381  ...  0.966330  0.968750  0.972835   \n",
       "734  0.941636  0.944067  0.949606  ...  0.970248  0.974210  0.970785   \n",
       "735  0.903075  0.903293  0.902887  ...  0.945185  0.950480  0.956458   \n",
       "736  0.895779  0.904861  0.915486  ...  0.996315  0.994842  0.994092   \n",
       "\n",
       "          225       226  227  228  229  230  label  \n",
       "0    0.920792  0.115385  1.0  1.0  0.0  0.0     CL  \n",
       "1    0.980198  0.403846  1.0  1.0  0.0  1.0     CL  \n",
       "2    0.297030  0.346154  0.0  1.0  0.0  1.0     CL  \n",
       "3    0.297030  0.346154  0.0  1.0  0.0  1.0     CL  \n",
       "4    0.297030  0.326923  0.0  1.0  0.0  1.0     CL  \n",
       "..        ...       ...  ...  ...  ...  ...    ...  \n",
       "732  0.940594  0.884615  1.0  1.0  1.0  1.0   NROI  \n",
       "733  0.940594  0.980769  1.0  1.0  1.0  1.0   NROI  \n",
       "734  0.742574  0.923077  1.0  0.0  1.0  1.0   NROI  \n",
       "735  0.762376  0.865385  1.0  1.0  1.0  1.0   NROI  \n",
       "736  0.841584  1.000000  1.0  1.0  1.0  1.0   NROI  \n",
       "\n",
       "[737 rows x 457 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#D:\\ClimateChange\\RawData\\ROI_Pressure\\MinMax\n",
    "data =  pd.read_csv('../RawData/ROI_Pressure/MinMax/year2_minmax_cutfirst_normfirst_xy_map.csv',index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43b61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data.iloc[:,:456]\n",
    "data_y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe7748f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>221.1</th>\n",
       "      <th>222.1</th>\n",
       "      <th>223.1</th>\n",
       "      <th>224.1</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266183</td>\n",
       "      <td>0.267322</td>\n",
       "      <td>0.267839</td>\n",
       "      <td>0.268356</td>\n",
       "      <td>0.269669</td>\n",
       "      <td>0.271125</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.274101</td>\n",
       "      <td>0.276006</td>\n",
       "      <td>0.277690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.024460</td>\n",
       "      <td>0.024566</td>\n",
       "      <td>0.025473</td>\n",
       "      <td>0.920792</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.548938</td>\n",
       "      <td>0.548604</td>\n",
       "      <td>0.548087</td>\n",
       "      <td>0.547053</td>\n",
       "      <td>0.546066</td>\n",
       "      <td>0.545360</td>\n",
       "      <td>0.544935</td>\n",
       "      <td>0.543512</td>\n",
       "      <td>0.542081</td>\n",
       "      <td>0.540682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386431</td>\n",
       "      <td>0.390762</td>\n",
       "      <td>0.397230</td>\n",
       "      <td>0.405797</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357846</td>\n",
       "      <td>0.355222</td>\n",
       "      <td>0.353671</td>\n",
       "      <td>0.352637</td>\n",
       "      <td>0.352484</td>\n",
       "      <td>0.353033</td>\n",
       "      <td>0.354286</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.358599</td>\n",
       "      <td>0.361680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062123</td>\n",
       "      <td>0.064879</td>\n",
       "      <td>0.068301</td>\n",
       "      <td>0.073843</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.357846</td>\n",
       "      <td>0.355222</td>\n",
       "      <td>0.353671</td>\n",
       "      <td>0.352637</td>\n",
       "      <td>0.352484</td>\n",
       "      <td>0.353033</td>\n",
       "      <td>0.354286</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.358599</td>\n",
       "      <td>0.361680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062123</td>\n",
       "      <td>0.064879</td>\n",
       "      <td>0.068301</td>\n",
       "      <td>0.073843</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.395650</td>\n",
       "      <td>0.389866</td>\n",
       "      <td>0.385729</td>\n",
       "      <td>0.382110</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>0.378953</td>\n",
       "      <td>0.378182</td>\n",
       "      <td>0.378843</td>\n",
       "      <td>0.378986</td>\n",
       "      <td>0.380577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037005</td>\n",
       "      <td>0.038095</td>\n",
       "      <td>0.039508</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>0.859658</td>\n",
       "      <td>0.870734</td>\n",
       "      <td>0.885212</td>\n",
       "      <td>0.897622</td>\n",
       "      <td>0.903209</td>\n",
       "      <td>0.907206</td>\n",
       "      <td>0.908052</td>\n",
       "      <td>0.908286</td>\n",
       "      <td>0.905907</td>\n",
       "      <td>0.900787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934562</td>\n",
       "      <td>0.923706</td>\n",
       "      <td>0.930254</td>\n",
       "      <td>0.939836</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0.916624</td>\n",
       "      <td>0.919855</td>\n",
       "      <td>0.928128</td>\n",
       "      <td>0.934333</td>\n",
       "      <td>0.938406</td>\n",
       "      <td>0.943494</td>\n",
       "      <td>0.947013</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>0.952953</td>\n",
       "      <td>0.955381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964795</td>\n",
       "      <td>0.966330</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.972835</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>0.932160</td>\n",
       "      <td>0.934850</td>\n",
       "      <td>0.934850</td>\n",
       "      <td>0.935884</td>\n",
       "      <td>0.937371</td>\n",
       "      <td>0.938310</td>\n",
       "      <td>0.940260</td>\n",
       "      <td>0.941636</td>\n",
       "      <td>0.944067</td>\n",
       "      <td>0.949606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969522</td>\n",
       "      <td>0.970248</td>\n",
       "      <td>0.974210</td>\n",
       "      <td>0.970785</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0.879855</td>\n",
       "      <td>0.885729</td>\n",
       "      <td>0.891417</td>\n",
       "      <td>0.895553</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.900985</td>\n",
       "      <td>0.902338</td>\n",
       "      <td>0.903075</td>\n",
       "      <td>0.903293</td>\n",
       "      <td>0.902887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940565</td>\n",
       "      <td>0.945185</td>\n",
       "      <td>0.950480</td>\n",
       "      <td>0.956458</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.868980</td>\n",
       "      <td>0.876422</td>\n",
       "      <td>0.886763</td>\n",
       "      <td>0.889866</td>\n",
       "      <td>0.889234</td>\n",
       "      <td>0.883359</td>\n",
       "      <td>0.889870</td>\n",
       "      <td>0.895779</td>\n",
       "      <td>0.904861</td>\n",
       "      <td>0.915486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996321</td>\n",
       "      <td>0.996315</td>\n",
       "      <td>0.994842</td>\n",
       "      <td>0.994092</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>737 rows × 456 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.266183  0.267322  0.267839  0.268356  0.269669  0.271125  0.272727   \n",
       "1    0.548938  0.548604  0.548087  0.547053  0.546066  0.545360  0.544935   \n",
       "2    0.357846  0.355222  0.353671  0.352637  0.352484  0.353033  0.354286   \n",
       "3    0.357846  0.355222  0.353671  0.352637  0.352484  0.353033  0.354286   \n",
       "4    0.395650  0.389866  0.385729  0.382110  0.380435  0.378953  0.378182   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "732  0.859658  0.870734  0.885212  0.897622  0.903209  0.907206  0.908052   \n",
       "733  0.916624  0.919855  0.928128  0.934333  0.938406  0.943494  0.947013   \n",
       "734  0.932160  0.934850  0.934850  0.935884  0.937371  0.938310  0.940260   \n",
       "735  0.879855  0.885729  0.891417  0.895553  0.898551  0.900985  0.902338   \n",
       "736  0.868980  0.876422  0.886763  0.889866  0.889234  0.883359  0.889870   \n",
       "\n",
       "            7         8         9  ...     221.1     222.1     223.1  \\\n",
       "0    0.274101  0.276006  0.277690  ...  0.022989  0.024460  0.024566   \n",
       "1    0.543512  0.542081  0.540682  ...  0.386431  0.390762  0.397230   \n",
       "2    0.356436  0.358599  0.361680  ...  0.062123  0.064879  0.068301   \n",
       "3    0.356436  0.358599  0.361680  ...  0.062123  0.064879  0.068301   \n",
       "4    0.378843  0.378986  0.380577  ...  0.037005  0.038095  0.039508   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "732  0.908286  0.905907  0.900787  ...  0.934562  0.923706  0.930254   \n",
       "733  0.950495  0.952953  0.955381  ...  0.964795  0.966330  0.968750   \n",
       "734  0.941636  0.944067  0.949606  ...  0.969522  0.970248  0.974210   \n",
       "735  0.903075  0.903293  0.902887  ...  0.940565  0.945185  0.950480   \n",
       "736  0.895779  0.904861  0.915486  ...  0.996321  0.996315  0.994842   \n",
       "\n",
       "        224.1       225       226  227  228  229  230  \n",
       "0    0.025473  0.920792  0.115385  1.0  1.0  0.0  0.0  \n",
       "1    0.405797  0.980198  0.403846  1.0  1.0  0.0  1.0  \n",
       "2    0.073843  0.297030  0.346154  0.0  1.0  0.0  1.0  \n",
       "3    0.073843  0.297030  0.346154  0.0  1.0  0.0  1.0  \n",
       "4    0.041927  0.297030  0.326923  0.0  1.0  0.0  1.0  \n",
       "..        ...       ...       ...  ...  ...  ...  ...  \n",
       "732  0.939836  0.940594  0.884615  1.0  1.0  1.0  1.0  \n",
       "733  0.972835  0.940594  0.980769  1.0  1.0  1.0  1.0  \n",
       "734  0.970785  0.742574  0.923077  1.0  0.0  1.0  1.0  \n",
       "735  0.956458  0.762376  0.865385  1.0  1.0  1.0  1.0  \n",
       "736  0.994092  0.841584  1.000000  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[737 rows x 456 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1830ba1",
   "metadata": {},
   "source": [
    "# Kmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2375a380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0,\n",
       "       0, 3, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0,\n",
       "       2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "       0, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 0, 0, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 0,\n",
       "       1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 0, 2, 2, 1, 1, 2, 2, 3, 2, 3, 3, 0,\n",
       "       3, 3, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0,\n",
       "       0, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1, 0, 1, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 1, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 2, 1, 1, 1, 0, 2, 0, 0, 1, 1, 0, 1, 1, 2, 0, 2, 2, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0,\n",
       "       0, 2, 2, 1, 1, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 2, 1, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 3, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 0, 3, 1, 1, 1,\n",
       "       2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 0, 2, 2, 2, 1, 3, 0, 0, 0, 0, 2, 2,\n",
       "       2, 2, 0, 0, 2, 2, 2, 0, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters =4).fit(data_x)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fffcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../RawData/ROI_Pressure/Unnormed/year2_xy_unnormed.csv'\n",
    "results = []\n",
    "result_label = []\n",
    "for a in range (4):\n",
    "    for b in range (4):\n",
    "        for c in range (4):\n",
    "            for d in range (4):\n",
    "                data =  pd.read_csv(path,index_col=0)\n",
    "                data_y = data['label']\n",
    "                for i in range(0,data_y.shape[0]):\n",
    "                    if data_y[i] == 'CL':\n",
    "                        data_y[i]=a\n",
    "                    if data_y[i] == 'COH':\n",
    "                        data_y[i]=b\n",
    "                    if data_y[i] == 'COL':\n",
    "                        data_y[i]=c\n",
    "                    if data_y[i] == 'NROI':\n",
    "                        data_y[i]=d\n",
    "                    if(a==b or a==c or a==d or b==c or b==d or c==d):\n",
    "                        continue\n",
    "                    result = sum(1 for x,y in zip(data_y,kmeans.labels_) if x == y) / len(kmeans.labels_)\n",
    "                    results.append(result)\n",
    "                    result_label.append([a,b,c,d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b0f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = results.copy()\n",
    "index = np.argsort(temp)\n",
    "print(\"max result is :\" + str(max(results))+ \"and the label for CL, COL, COH, and NROI is :\" + str(result_label[index[-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92dd98",
   "metadata": {},
   "source": [
    "# Som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcaeba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  pd.read_csv('../RawData/ROI_Pressure/MinMax/year2_minmax_cutfirst_normfirst_xy_map.csv',index_col=0)\n",
    "data_x = data.iloc[:,:456]\n",
    "data_y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46d0c728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        CL\n",
       "1        CL\n",
       "2        CL\n",
       "3        CL\n",
       "4        CL\n",
       "       ... \n",
       "732    NROI\n",
       "733    NROI\n",
       "734    NROI\n",
       "735    NROI\n",
       "736    NROI\n",
       "Name: label, Length: 737, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f6b5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# Data Normalization\n",
    "def minmax_scaler(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(data)\n",
    "    return scaled\n",
    "\n",
    "# Euclidean distance\n",
    "def e_distance(x,y):\n",
    "    return distance.euclidean(x,y)\n",
    "\n",
    "# Manhattan distance\n",
    "def m_distance(x,y):\n",
    "    return distance.cityblock(x,y)\n",
    "\n",
    "# Best Matching Unit search\n",
    "def winning_neuron(data, t, som, num_rows, num_cols):\n",
    "    winner = [0,0]\n",
    "    shortest_distance = np.sqrt(data.shape[1]) # initialise with max distance\n",
    "    input_data = data.iloc[t]\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            distance = e_distance(som[row][col], data.iloc[t])\n",
    "            if distance < shortest_distance: \n",
    "                shortest_distance = distance\n",
    "                winner = [row,col]\n",
    "    return winner\n",
    "\n",
    "# Learning rate and neighbourhood range calculation\n",
    "def decay(step, max_steps,max_learning_rate,max_m_dsitance):\n",
    "    coefficient = 1.0 - (np.float64(step)/max_steps)\n",
    "    learning_rate = coefficient*max_learning_rate\n",
    "    neighbourhood_range = ceil(coefficient * max_m_dsitance)\n",
    "    return learning_rate, neighbourhood_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "714694fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "num_rows = 10\n",
    "num_cols = 10\n",
    "max_m_dsitance = 4\n",
    "max_learning_rate = 0.5\n",
    "max_steps = int(50000)\n",
    "\n",
    "# num_nurons = 5*np.sqrt(train_x.shape[0])\n",
    "# grid_size = ceil(np.sqrt(num_nurons))\n",
    "# print(grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09dd6001",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m learning_rate, neighbourhood_range \u001b[38;5;241m=\u001b[39m decay(step, max_steps,max_learning_rate,max_m_dsitance)\n\u001b[0;32m     14\u001b[0m t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,high\u001b[38;5;241m=\u001b[39mtrain_x_norm\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;66;03m# random index of traing data\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m winner \u001b[38;5;241m=\u001b[39m \u001b[43mwinning_neuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_cols\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m##########################################\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_rows):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_cols):\n",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36mwinning_neuron\u001b[1;34m(data, t, som, num_rows, num_cols)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_rows):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_cols):\n\u001b[1;32m---> 24\u001b[0m         distance \u001b[38;5;241m=\u001b[39m \u001b[43me_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43msom\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m distance \u001b[38;5;241m<\u001b[39m shortest_distance: \n\u001b[0;32m     26\u001b[0m             shortest_distance \u001b[38;5;241m=\u001b[39m distance\n",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36me_distance\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21me_distance\u001b[39m(x,y):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdistance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meuclidean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\spatial\\distance.py:597\u001b[0m, in \u001b[0;36meuclidean\u001b[1;34m(u, v, w)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meuclidean\u001b[39m(u, v, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;124;03m    Computes the Euclidean distance between two 1-D arrays.\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    595\u001b[0m \n\u001b[0;32m    596\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mminkowski\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\spatial\\distance.py:485\u001b[0m, in \u001b[0;36mminkowski\u001b[1;34m(u, v, p, w)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mCompute the Minkowski distance between two 1-D arrays.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m \n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m u \u001b[38;5;241m=\u001b[39m _validate_vector(u)\n\u001b[1;32m--> 485\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp must be at least 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\spatial\\distance.py:300\u001b[0m, in \u001b[0;36m_validate_vector\u001b[1;34m(u, dtype)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_vector\u001b[39m(u, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# XXX Is order='c' really necessary?\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m u\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m u\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#main function\n",
    "\n",
    "# initialising self-organising map\n",
    "num_dims = train_x_norm.shape[1] # numnber of dimensions in the input data\n",
    "np.random.seed(40)\n",
    "som = np.random.random_sample(size=(num_rows, num_cols, num_dims)) # map construction\n",
    "\n",
    "# start training iterations\n",
    "for step in range(max_steps):\n",
    "    if (step+1) % 5000 == 0:\n",
    "        print(\"Iteration: \", step+1) # print out the current iteration for every 5k\n",
    "    learning_rate, neighbourhood_range = decay(step, max_steps,max_learning_rate,max_m_dsitance)\n",
    "\n",
    "    t = np.random.randint(0,high=train_x_norm.shape[0]) # random index of traing data\n",
    "    winner = winning_neuron(train_x_norm, t, som, num_rows, num_cols) ##########################################\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            if m_distance([row,col],winner) <= neighbourhood_range:\n",
    "                som[row][col] += learning_rate*(train_x_norm.iloc[t]-som[row][col]) #update neighbour's weight\n",
    "\n",
    "print(\"SOM training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0d6e42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.59026253, 0.59190874, 0.59367874, ..., 0.6045202 ,\n",
       "         0.62713785, 0.176654  ],\n",
       "        [0.59965382, 0.59842872, 0.59771647, ..., 0.589554  ,\n",
       "         0.79632781, 0.15623891],\n",
       "        [0.58501681, 0.5825662 , 0.58071092, ..., 0.56809901,\n",
       "         0.81759047, 0.13815043],\n",
       "        ...,\n",
       "        [0.34121314, 0.33894456, 0.33685604, ..., 0.32198989,\n",
       "         0.8855405 , 0.25739367],\n",
       "        [0.23120295, 0.23027593, 0.2295343 , ..., 0.22050543,\n",
       "         0.79406705, 0.1422172 ],\n",
       "        [0.19425777, 0.19317014, 0.19230482, ..., 0.17959774,\n",
       "         0.72289251, 0.10101934]],\n",
       "\n",
       "       [[0.57531293, 0.57896952, 0.58256367, ..., 0.62770272,\n",
       "         0.55634835, 0.14953561],\n",
       "        [0.59887623, 0.59950022, 0.60041756, ..., 0.6100034 ,\n",
       "         0.72936998, 0.16109869],\n",
       "        [0.59131842, 0.5884245 , 0.58620551, ..., 0.57685279,\n",
       "         0.86053999, 0.16361948],\n",
       "        ...,\n",
       "        [0.31768655, 0.31652487, 0.31570408, ..., 0.31328475,\n",
       "         0.72079425, 0.23555803],\n",
       "        [0.27800401, 0.2779596 , 0.27813095, ..., 0.27739358,\n",
       "         0.76329528, 0.18199714],\n",
       "        [0.21716221, 0.21626791, 0.21557342, ..., 0.20591054,\n",
       "         0.7325669 , 0.13182253]],\n",
       "\n",
       "       [[0.58957402, 0.59420624, 0.59892966, ..., 0.65362856,\n",
       "         0.51379921, 0.13982048],\n",
       "        [0.60193952, 0.60414182, 0.60644312, ..., 0.6501991 ,\n",
       "         0.6732188 , 0.15737492],\n",
       "        [0.642456  , 0.63965774, 0.63752603, ..., 0.64361457,\n",
       "         0.89752307, 0.43365462],\n",
       "        ...,\n",
       "        [0.3745707 , 0.37404125, 0.3739526 , ..., 0.39372707,\n",
       "         0.55251933, 0.24732783],\n",
       "        [0.31637279, 0.31635435, 0.31655505, ..., 0.32679276,\n",
       "         0.65406077, 0.20868505],\n",
       "        [0.30376228, 0.30358445, 0.30361488, ..., 0.30841499,\n",
       "         0.61448228, 0.19757453]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.94982397, 0.95066795, 0.95196594, ..., 0.96878877,\n",
       "         0.77991132, 0.89699071],\n",
       "        [0.95667365, 0.95684368, 0.95718899, ..., 0.96586766,\n",
       "         0.73737994, 0.90053999],\n",
       "        [0.94144954, 0.94227748, 0.94360482, ..., 0.95432931,\n",
       "         0.553636  , 0.85679005],\n",
       "        ...,\n",
       "        [0.74653539, 0.74567476, 0.74516892, ..., 0.78469008,\n",
       "         0.35226076, 0.42842134],\n",
       "        [0.70376391, 0.69938146, 0.69525436, ..., 0.73832488,\n",
       "         0.30620354, 0.47393499],\n",
       "        [0.71062026, 0.70103166, 0.69202293, ..., 0.70968933,\n",
       "         0.23613728, 0.58340812]],\n",
       "\n",
       "       [[0.9420017 , 0.94395068, 0.94646208, ..., 0.98001862,\n",
       "         0.70368045, 0.89714639],\n",
       "        [0.9335605 , 0.93693216, 0.94093825, ..., 0.97609657,\n",
       "         0.58411225, 0.87158566],\n",
       "        [0.91136801, 0.91566624, 0.92039117, ..., 0.9680823 ,\n",
       "         0.3310833 , 0.82717007],\n",
       "        ...,\n",
       "        [0.71064812, 0.71400148, 0.71769715, ..., 0.77370387,\n",
       "         0.37376933, 0.21636087],\n",
       "        [0.73167529, 0.73312706, 0.73492046, ..., 0.77052812,\n",
       "         0.31530965, 0.39388825],\n",
       "        [0.73990768, 0.73656561, 0.73259594, ..., 0.75416584,\n",
       "         0.23094958, 0.70953464]],\n",
       "\n",
       "       [[0.92409872, 0.92839148, 0.9335938 , ..., 0.98250538,\n",
       "         0.60137539, 0.87552094],\n",
       "        [0.91429823, 0.91971693, 0.92600677, ..., 0.98273254,\n",
       "         0.54569268, 0.85609041],\n",
       "        [0.89292773, 0.89969564, 0.90708931, ..., 0.97110946,\n",
       "         0.40408223, 0.78131904],\n",
       "        ...,\n",
       "        [0.73588218, 0.7382055 , 0.74097626, ..., 0.78240315,\n",
       "         0.33923786, 0.25652125],\n",
       "        [0.76189319, 0.76198272, 0.76185842, ..., 0.77711624,\n",
       "         0.29566003, 0.46964523],\n",
       "        [0.76436129, 0.76341415, 0.76215415, ..., 0.77409996,\n",
       "         0.26762662, 0.59890173]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "som"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377fb84",
   "metadata": {},
   "source": [
    "# 0-Cl 1-COL 2-COH 3-NROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10facee1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    " \n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "data_y_label = le.fit_transform(data_y)\n",
    " \n",
    "# printing label\n",
    "data_y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a52640b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting labels\n",
    "\n",
    "label_data = data_y_label\n",
    "map = np.empty(shape=(num_rows, num_cols), dtype=object)\n",
    "\n",
    "for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "        map[row][col] = [] # empty list to store the label\n",
    "\n",
    "for t in range(train_x_norm.shape[0]):\n",
    "    if (t+1) % 1000 == 0:\n",
    "        print(\"sample data: \", t+1)\n",
    "    winner = winning_neuron(train_x_norm, t, som, num_rows, num_cols)\n",
    "    map[winner[0]][winner[1]].append(label_data[t]) # label of winning neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "482cad19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#after mapping x and y: 10 by 10 50000\n",
    "# construct label map\n",
    "label_map = np.zeros(shape=(num_rows, num_cols),dtype=np.int64)\n",
    "for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "        label_list = map[row][col]\n",
    "        if len(label_list)==0:\n",
    "            label = 4\n",
    "        else:\n",
    "            label = max(label_list, key=label_list.count)\n",
    "        label_map[row][col] = label\n",
    "\n",
    "title = ('Iteration ' + str(max_steps))\n",
    "cmap = colors.ListedColormap(['tab:green', 'tab:red', 'tab:blue','tab:orange','tab:purple'])\n",
    "plt.imshow(label_map, cmap=cmap)\n",
    "plt.colorbar()\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c5f02ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 2, 0, 0, 0],\n",
       "       [1, 2, 2, 2, 0, 4, 4, 0, 0, 0],\n",
       "       [1, 2, 2, 4, 2, 2, 2, 2, 0, 0],\n",
       "       [2, 2, 2, 2, 4, 2, 0, 2, 2, 2],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "       [3, 2, 2, 0, 2, 2, 2, 2, 2, 2],\n",
       "       [3, 3, 2, 2, 2, 2, 2, 2, 4, 2],\n",
       "       [1, 2, 3, 2, 2, 3, 2, 1, 4, 2],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 2, 2]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0-Cl 1-COL 2-COH 3-NROI\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f6391be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8534599728629579\n"
     ]
    }
   ],
   "source": [
    "data = minmax_scaler(data_x) # normalisation\n",
    "\n",
    "winner_labels = []\n",
    "\n",
    "for t in range(data.shape[0]):\n",
    "    winner = winning_neuron(data, t, som, num_rows, num_cols)\n",
    "    row = winner[0]\n",
    "    col = winner[1]\n",
    "    predicted = label_map[row][col]\n",
    "    winner_labels.append(predicted)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(data_y_label, np.array(winner_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c62e351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 3, 2, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 0, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3, 3, 2, 2, 3, 3, 3, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 2, 1, 0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 2, 3, 3, 3, 2, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 1, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(winner_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f120742",
   "metadata": {},
   "source": [
    "# Acc for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e148b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 178, 1: 161, 2: 327, 3: 71}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(data_y_label, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cb959c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_CL: 0.8764044943820225, acc_COL: 0.8944099378881988, acc_COH: 0.8593272171253823, acc_NROI: 0.676056338028169\n"
     ]
    }
   ],
   "source": [
    "#accuracy for each label\n",
    "#0-Cl 1-COL 2-COH 3-NROI\n",
    "acc_cl = sum(1 for x in winner_labels[:178] if x == 0) / 178\n",
    "acc_coh = sum(1 for x in winner_labels[178:505] if x == 2) / 327\n",
    "acc_col = sum(1 for x in winner_labels[505:666] if x == 1) / 161\n",
    "acc_nroi = sum(1 for x in winner_labels[666:] if x == 3) / 71\n",
    "print(f\"acc_CL: {acc_cl}, acc_COL: {acc_col}, acc_COH: {acc_coh}, acc_NROI: {acc_nroi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b83e688b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "among all the CL records:\n",
      "156 were classified as CL\n",
      "22 were classified as COH\n",
      "----------\n",
      "among all the COL records:\n",
      "5 were classified as CL\n",
      "144 were classified as COL\n",
      "10 were classified as COH\n",
      "2 were classified as NROI\n",
      "---------\n",
      "among all the COH records:\n",
      "25 were classified as CL\n",
      "2 were classified as COL\n",
      "281 were classified as COH\n",
      "19 were classified as NROI\n",
      "---------\n",
      "among all the NROI records:\n",
      "4 were classified as COL\n",
      "19 were classified as COH\n",
      "48 were classified as NROI\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(winner_labels[:178], return_counts=True)\n",
    "print('among all the CL records:')\n",
    "for i in range(2):\n",
    "    temp = unique[i]\n",
    "    if temp == 0:\n",
    "        temp = 'CL'\n",
    "    if temp == 1:\n",
    "        temp = 'COL'\n",
    "    if temp == 2:\n",
    "        temp = 'COH'\n",
    "    if temp == 3:\n",
    "        temp = 'NROI'\n",
    "    print(f'{counts[i]} were classified as {temp}')\n",
    "print(\"----------\")\n",
    "\n",
    "unique, counts = np.unique(winner_labels[505:666], return_counts=True)\n",
    "print('among all the COL records:')\n",
    "for i in range(4):\n",
    "    temp = unique[i]\n",
    "    if temp == 0:\n",
    "        temp = 'CL'\n",
    "    if temp == 1:\n",
    "        temp = 'COL'\n",
    "    if temp == 2:\n",
    "        temp = 'COH'\n",
    "    if temp == 3:\n",
    "        temp = 'NROI'\n",
    "    print(f'{counts[i]} were classified as {temp}')\n",
    "print(\"---------\")\n",
    "\n",
    "\n",
    "unique, counts = np.unique(winner_labels[178:505], return_counts=True)\n",
    "print('among all the COH records:')\n",
    "for i in range(4):\n",
    "    temp = unique[i]\n",
    "    if temp == 0:\n",
    "        temp = 'CL'\n",
    "    if temp == 1:\n",
    "        temp = 'COL'\n",
    "    if temp == 2:\n",
    "        temp = 'COH'\n",
    "    if temp == 3:\n",
    "        temp = 'NROI'\n",
    "    print(f'{counts[i]} were classified as {temp}')\n",
    "    \n",
    "print(\"---------\")\n",
    "    \n",
    "unique, counts = np.unique(winner_labels[666:], return_counts=True)\n",
    "print('among all the NROI records:')\n",
    "for i in range(3):\n",
    "    temp = unique[i]\n",
    "    if temp == 0:\n",
    "        temp = 'CL'\n",
    "    if temp == 1:\n",
    "        temp = 'COL'\n",
    "    if temp == 2:\n",
    "        temp = 'COH'\n",
    "    if temp == 3:\n",
    "        temp = 'NROI'\n",
    "    print(f'{counts[i]} were classified as {temp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb7ba05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
