{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6dc4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.ma.core import ceil\n",
    "from scipy.spatial import distance #distance calculation\n",
    "from sklearn.preprocessing import MinMaxScaler #normalisation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score #scoring\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import animation, colors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "214bc26e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.329231</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.326154</td>\n",
       "      <td>0.323692</td>\n",
       "      <td>0.321231</td>\n",
       "      <td>0.318769</td>\n",
       "      <td>0.316923</td>\n",
       "      <td>0.315077</td>\n",
       "      <td>0.312615</td>\n",
       "      <td>0.310154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339692</td>\n",
       "      <td>0.336615</td>\n",
       "      <td>0.336615</td>\n",
       "      <td>0.335385</td>\n",
       "      <td>0.336615</td>\n",
       "      <td>0.339077</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>58.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.139692</td>\n",
       "      <td>0.139077</td>\n",
       "      <td>0.137846</td>\n",
       "      <td>0.137231</td>\n",
       "      <td>0.137231</td>\n",
       "      <td>0.137231</td>\n",
       "      <td>0.137846</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.140308</td>\n",
       "      <td>0.142154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084308</td>\n",
       "      <td>0.081231</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.082462</td>\n",
       "      <td>0.086154</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.102769</td>\n",
       "      <td>94.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.475692</td>\n",
       "      <td>0.473846</td>\n",
       "      <td>0.471385</td>\n",
       "      <td>0.468923</td>\n",
       "      <td>0.465846</td>\n",
       "      <td>0.462769</td>\n",
       "      <td>0.460308</td>\n",
       "      <td>0.456615</td>\n",
       "      <td>0.453538</td>\n",
       "      <td>0.450462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422769</td>\n",
       "      <td>0.422154</td>\n",
       "      <td>0.423385</td>\n",
       "      <td>0.425846</td>\n",
       "      <td>0.429538</td>\n",
       "      <td>0.435077</td>\n",
       "      <td>0.443077</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.248615</td>\n",
       "      <td>0.243692</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.237538</td>\n",
       "      <td>0.235692</td>\n",
       "      <td>0.234462</td>\n",
       "      <td>0.234462</td>\n",
       "      <td>0.235692</td>\n",
       "      <td>0.237538</td>\n",
       "      <td>0.240615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.214154</td>\n",
       "      <td>0.216615</td>\n",
       "      <td>0.222769</td>\n",
       "      <td>0.232615</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.264615</td>\n",
       "      <td>31.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.248615</td>\n",
       "      <td>0.243692</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.237538</td>\n",
       "      <td>0.235692</td>\n",
       "      <td>0.234462</td>\n",
       "      <td>0.234462</td>\n",
       "      <td>0.235692</td>\n",
       "      <td>0.237538</td>\n",
       "      <td>0.240615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.214154</td>\n",
       "      <td>0.216615</td>\n",
       "      <td>0.222769</td>\n",
       "      <td>0.232615</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.264615</td>\n",
       "      <td>31.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.844923</td>\n",
       "      <td>0.857231</td>\n",
       "      <td>0.872615</td>\n",
       "      <td>0.886154</td>\n",
       "      <td>0.890462</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.890462</td>\n",
       "      <td>0.887385</td>\n",
       "      <td>0.881846</td>\n",
       "      <td>0.872615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.889846</td>\n",
       "      <td>0.887385</td>\n",
       "      <td>0.889231</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.899077</td>\n",
       "      <td>0.900308</td>\n",
       "      <td>91.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0.912615</td>\n",
       "      <td>0.915692</td>\n",
       "      <td>0.923692</td>\n",
       "      <td>0.929846</td>\n",
       "      <td>0.932308</td>\n",
       "      <td>0.935385</td>\n",
       "      <td>0.936615</td>\n",
       "      <td>0.937231</td>\n",
       "      <td>0.937231</td>\n",
       "      <td>0.936615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932923</td>\n",
       "      <td>0.929846</td>\n",
       "      <td>0.927385</td>\n",
       "      <td>0.926154</td>\n",
       "      <td>0.926769</td>\n",
       "      <td>0.927385</td>\n",
       "      <td>0.928615</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0.931077</td>\n",
       "      <td>0.933538</td>\n",
       "      <td>0.931692</td>\n",
       "      <td>0.931692</td>\n",
       "      <td>0.931077</td>\n",
       "      <td>0.929231</td>\n",
       "      <td>0.928615</td>\n",
       "      <td>0.926769</td>\n",
       "      <td>0.926769</td>\n",
       "      <td>0.929846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921231</td>\n",
       "      <td>0.920615</td>\n",
       "      <td>0.921846</td>\n",
       "      <td>0.921846</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.920615</td>\n",
       "      <td>0.921846</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0.868923</td>\n",
       "      <td>0.875077</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.883692</td>\n",
       "      <td>0.884923</td>\n",
       "      <td>0.884923</td>\n",
       "      <td>0.883692</td>\n",
       "      <td>0.881231</td>\n",
       "      <td>0.878769</td>\n",
       "      <td>0.875077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877538</td>\n",
       "      <td>0.881846</td>\n",
       "      <td>0.887385</td>\n",
       "      <td>0.892923</td>\n",
       "      <td>0.898462</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.913846</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.874462</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.873846</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.868923</td>\n",
       "      <td>0.872615</td>\n",
       "      <td>0.880615</td>\n",
       "      <td>0.889846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937231</td>\n",
       "      <td>0.937846</td>\n",
       "      <td>0.936615</td>\n",
       "      <td>0.935385</td>\n",
       "      <td>0.933538</td>\n",
       "      <td>0.931077</td>\n",
       "      <td>0.927385</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741 rows × 228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.329231  0.328000  0.326154  0.323692  0.321231  0.318769  0.316923   \n",
       "1    0.139692  0.139077  0.137846  0.137231  0.137231  0.137231  0.137846   \n",
       "2    0.475692  0.473846  0.471385  0.468923  0.465846  0.462769  0.460308   \n",
       "3    0.248615  0.243692  0.240000  0.237538  0.235692  0.234462  0.234462   \n",
       "4    0.248615  0.243692  0.240000  0.237538  0.235692  0.234462  0.234462   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "736  0.844923  0.857231  0.872615  0.886154  0.890462  0.892308  0.890462   \n",
       "737  0.912615  0.915692  0.923692  0.929846  0.932308  0.935385  0.936615   \n",
       "738  0.931077  0.933538  0.931692  0.931692  0.931077  0.929231  0.928615   \n",
       "739  0.868923  0.875077  0.880000  0.883692  0.884923  0.884923  0.883692   \n",
       "740  0.856000  0.864000  0.874462  0.876923  0.873846  0.864000  0.868923   \n",
       "\n",
       "            7         8         9  ...       218       219       220  \\\n",
       "0    0.315077  0.312615  0.310154  ...  0.339692  0.336615  0.336615   \n",
       "1    0.138462  0.140308  0.142154  ...  0.084308  0.081231  0.080000   \n",
       "2    0.456615  0.453538  0.450462  ...  0.422769  0.422154  0.423385   \n",
       "3    0.235692  0.237538  0.240615  ...  0.216000  0.214154  0.216615   \n",
       "4    0.235692  0.237538  0.240615  ...  0.216000  0.214154  0.216615   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "736  0.887385  0.881846  0.872615  ...  0.892308  0.889846  0.887385   \n",
       "737  0.937231  0.937231  0.936615  ...  0.932923  0.929846  0.927385   \n",
       "738  0.926769  0.926769  0.929846  ...  0.921231  0.920615  0.921846   \n",
       "739  0.881231  0.878769  0.875077  ...  0.877538  0.881846  0.887385   \n",
       "740  0.872615  0.880615  0.889846  ...  0.937231  0.937846  0.936615   \n",
       "\n",
       "          221       222       223       224    225   226  label  \n",
       "0    0.335385  0.336615  0.339077  0.341538   58.0  11.0     CL  \n",
       "1    0.082462  0.086154  0.092308  0.102769   94.0  17.0     CL  \n",
       "2    0.425846  0.429538  0.435077  0.443077  100.0  32.0     CL  \n",
       "3    0.222769  0.232615  0.246154  0.264615   31.0  29.0     CL  \n",
       "4    0.222769  0.232615  0.246154  0.264615   31.0  29.0     CL  \n",
       "..        ...       ...       ...       ...    ...   ...    ...  \n",
       "736  0.889231  0.896000  0.899077  0.900308   91.0  53.0   NROI  \n",
       "737  0.926154  0.926769  0.927385  0.928615   27.0  31.0   NROI  \n",
       "738  0.921846  0.923077  0.920615  0.921846   28.0  37.0   NROI  \n",
       "739  0.892923  0.898462  0.904000  0.913846   24.0  28.0   NROI  \n",
       "740  0.935385  0.933538  0.931077  0.927385   24.0  27.0   NROI  \n",
       "\n",
       "[741 rows x 228 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  pd.read_csv('year2data.csv',index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d43b61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data.iloc[:,:227]\n",
    "data_y = data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1830ba1",
   "metadata": {},
   "source": [
    "# Kmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2375a380",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\GPU\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\GPU\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 0, 0, 0, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 2,\n",
       "       3, 0, 0, 2, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 0, 3, 2, 3, 3, 3, 3, 3, 3,\n",
       "       0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3,\n",
       "       3, 2, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 2, 0, 0, 3, 1, 3, 2, 2, 0, 2, 3, 3, 3, 3, 3, 2, 0, 2, 3,\n",
       "       3, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       3, 2, 0, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 2, 2, 3, 3, 1, 3, 3, 2, 2, 2, 2,\n",
       "       2, 2, 3, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 1,\n",
       "       1, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 3, 0, 0, 2, 2, 2, 2, 3, 1, 3,\n",
       "       3, 0, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 2, 3, 2, 1, 2,\n",
       "       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 2, 3, 3, 3, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 2, 3, 0, 0, 0, 0, 0, 2, 3, 2, 2, 2, 3, 0,\n",
       "       0, 0, 0, 1, 1, 1, 3, 2, 1, 2, 1, 2, 1, 2, 1, 0, 1, 0, 1, 0, 0, 2,\n",
       "       2, 2, 0, 1, 0, 1, 0, 1, 1, 3, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       3, 1, 0, 1, 0, 1, 0, 1, 2, 1, 1, 1, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 3, 3, 2, 2, 2, 3, 2, 3, 3, 1, 0, 3, 2, 2, 1, 0, 2, 2,\n",
       "       2, 0, 0, 0, 2, 2, 2, 1, 0, 1, 1, 1, 0, 2, 2, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 0, 0, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3,\n",
       "       0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 2, 2, 3, 0, 2, 2, 2, 3, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2,\n",
       "       3, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1, 2, 3, 3, 0, 0,\n",
       "       0, 2, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 2, 1, 2, 2, 1, 1, 2, 0, 2, 1, 1, 1, 1, 1, 0, 0, 2, 0, 2,\n",
       "       0, 1, 0, 1, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1,\n",
       "       2, 2, 0, 1, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters =4).fit(data_x)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2fffcdd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ethan\\AppData\\Local\\Temp\\ipykernel_13244\\2214960798.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_y[i]=3\n",
      "C:\\Users\\Ethan\\AppData\\Local\\Temp\\ipykernel_13244\\2214960798.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_y[i]=0\n",
      "C:\\Users\\Ethan\\AppData\\Local\\Temp\\ipykernel_13244\\2214960798.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_y[i]=1\n",
      "C:\\Users\\Ethan\\AppData\\Local\\Temp\\ipykernel_13244\\2214960798.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_y[i]=2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1      3\n",
       "2      3\n",
       "3      3\n",
       "4      3\n",
       "      ..\n",
       "736    2\n",
       "737    2\n",
       "738    2\n",
       "739    2\n",
       "740    2\n",
       "Name: label, Length: 741, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  pd.read_csv('year2data.csv',index_col=0)\n",
    "data_y = data['label']\n",
    "for i in range(0,data_y.shape[0]):\n",
    "    if data_y[i] == 'CL':\n",
    "        data_y[i]=3\n",
    "    if data_y[i] == 'COH':\n",
    "        data_y[i]=0\n",
    "    if data_y[i] == 'COL':\n",
    "        data_y[i]=1\n",
    "    if data_y[i] == 'NROI':\n",
    "        data_y[i]=2\n",
    "data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f49cb53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5074224021592443"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for x,y in zip(data_y,kmeans.labels_) if x == y) / len(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92dd98",
   "metadata": {},
   "source": [
    "# Som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22f38ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(592, 227) (592,) (149, 227) (149,)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2, random_state=42)\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape) # check the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f6b5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# Data Normalization\n",
    "def minmax_scaler(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(data)\n",
    "    return scaled\n",
    "\n",
    "# Euclidean distance\n",
    "def e_distance(x,y):\n",
    "    return distance.euclidean(x,y)\n",
    "\n",
    "# Manhattan distance\n",
    "def m_distance(x,y):\n",
    "    return distance.cityblock(x,y)\n",
    "\n",
    "# Best Matching Unit search\n",
    "def winning_neuron(data, t, som, num_rows, num_cols):\n",
    "    winner = [0,0]\n",
    "    shortest_distance = np.sqrt(data.shape[1]) # initialise with max distance\n",
    "    input_data = data[t]\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            distance = e_distance(som[row][col], data[t])\n",
    "            if distance < shortest_distance: \n",
    "                shortest_distance = distance\n",
    "                winner = [row,col]\n",
    "    return winner\n",
    "\n",
    "# Learning rate and neighbourhood range calculation\n",
    "def decay(step, max_steps,max_learning_rate,max_m_dsitance):\n",
    "    coefficient = 1.0 - (np.float64(step)/max_steps)\n",
    "    learning_rate = coefficient*max_learning_rate\n",
    "    neighbourhood_range = ceil(coefficient * max_m_dsitance)\n",
    "    return learning_rate, neighbourhood_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "714694fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "num_rows = 10\n",
    "num_cols = 10\n",
    "max_m_dsitance = 4\n",
    "max_learning_rate = 0.5\n",
    "max_steps = int(7.5*10e3)\n",
    "\n",
    "# num_nurons = 5*np.sqrt(train_x.shape[0])\n",
    "# grid_size = ceil(np.sqrt(num_nurons))\n",
    "# print(grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09dd6001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  5000\n",
      "Iteration:  10000\n",
      "Iteration:  15000\n",
      "Iteration:  20000\n",
      "Iteration:  25000\n",
      "Iteration:  30000\n",
      "Iteration:  35000\n",
      "Iteration:  40000\n",
      "Iteration:  45000\n",
      "Iteration:  50000\n",
      "Iteration:  55000\n",
      "Iteration:  60000\n",
      "Iteration:  65000\n",
      "Iteration:  70000\n",
      "Iteration:  75000\n",
      "SOM training completed\n"
     ]
    }
   ],
   "source": [
    "#main function\n",
    "\n",
    "train_x_norm = minmax_scaler(train_x) # normalisation\n",
    "\n",
    "# initialising self-organising map\n",
    "num_dims = train_x_norm.shape[1] # numnber of dimensions in the input data\n",
    "np.random.seed(40)\n",
    "som = np.random.random_sample(size=(num_rows, num_cols, num_dims)) # map construction\n",
    "\n",
    "# start training iterations\n",
    "for step in range(max_steps):\n",
    "    if (step+1) % 5000 == 0:\n",
    "        print(\"Iteration: \", step+1) # print out the current iteration for every 5k\n",
    "    learning_rate, neighbourhood_range = decay(step, max_steps,max_learning_rate,max_m_dsitance)\n",
    "\n",
    "    t = np.random.randint(0,high=train_x_norm.shape[0]) # random index of traing data\n",
    "    winner = winning_neuron(train_x_norm, t, som, num_rows, num_cols)\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            if m_distance([row,col],winner) <= neighbourhood_range:\n",
    "                som[row][col] += learning_rate*(train_x_norm[t]-som[row][col]) #update neighbour's weight\n",
    "\n",
    "print(\"SOM training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dfaad652",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.drop(['index'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6bd729e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>592 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label\n",
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       3\n",
       "4       3\n",
       "..    ...\n",
       "587     3\n",
       "588     3\n",
       "589     0\n",
       "590     1\n",
       "591     3\n",
       "\n",
       "[592 rows x 1 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2d9f5e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [3]], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a52640b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting labels\n",
    "\n",
    "label_data = train_y.values\n",
    "map = np.empty(shape=(num_rows, num_cols), dtype=object)\n",
    "\n",
    "for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "        map[row][col] = [] # empty list to store the label\n",
    "\n",
    "for t in range(train_x_norm.shape[0]):\n",
    "    if (t+1) % 1000 == 0:\n",
    "        print(\"sample data: \", t+1)\n",
    "    winner = winning_neuron(train_x_norm, t, som, num_rows, num_cols)\n",
    "    map[winner[0]][winner[1]].append(label_data[t]) # label of winning neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d075fb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# construct label map\n",
    "label_map = np.zeros(shape=(num_rows, num_cols),dtype=np.int64)\n",
    "for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "        label_list = map[row][col]\n",
    "        if len(label_list)==0:\n",
    "            label = 3\n",
    "        else:\n",
    "            label = max(label_list, key=label_list.count)\n",
    "        label_map[row][col] = label\n",
    "\n",
    "title = ('Iteration ' + str(max_steps))\n",
    "cmap = colors.ListedColormap(['tab:green', 'tab:red', 'tab:blue','tab:orange'])\n",
    "plt.imshow(label_map, cmap=cmap)\n",
    "plt.colorbar()\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6fade000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7785234899328859\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "\n",
    "# using the trained som, search the winning node of corresponding to the test data\n",
    "# get the label of the winning node\n",
    "\n",
    "data = minmax_scaler(test_x) # normalisation\n",
    "\n",
    "winner_labels = []\n",
    "\n",
    "for t in range(data.shape[0]):\n",
    "    winner = winning_neuron(data, t, som, num_rows, num_cols)\n",
    "    row = winner[0]\n",
    "    col = winner[1]\n",
    "    predicted = label_map[row][col]\n",
    "    winner_labels.append(predicted)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(test_y.astype(int), np.array(winner_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558f792a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
